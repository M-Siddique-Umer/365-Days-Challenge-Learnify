{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOrFxp7hBD4ZQLY0zJCHLsy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/M-Siddique-Umer/365-Days-Challenge-Learnify/blob/main/updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 1"
      ],
      "metadata": {
        "id": "rwntCOWzeJw2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hfY7fVC0bHws"
      },
      "outputs": [],
      "source": [
        "# ===================== Importing Required Libraries =====================\n",
        "# Importing pandas for data manipulation and numpy for numerical operations\n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (a) =====================\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "# Specify the path to the CSV file that contains the data\n",
        "df = pd.read_csv(\"/content/3d_printing.csv\")\n"
      ],
      "metadata": {
        "id": "uBuryOrZbM9K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop any rows where the \"Temperature\" column has NaN values\n",
        "# This ensures that we only analyze rows with valid temperature data\n",
        "df.dropna(subset=[\"Temperature\"], inplace=True)\n"
      ],
      "metadata": {
        "id": "b4KKz1ZTbOFn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the mean of the \"Temperature\" column\n",
        "mean_temp = df[\"Temperature\"].mean()\n",
        "\n",
        "# Calculate the standard deviation of the \"Temperature\" column\n",
        "std_temp = df[\"Temperature\"].std()\n"
      ],
      "metadata": {
        "id": "TprOdUOZbPPd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results for Part (a)\n",
        "# Displaying the mean and standard deviation of the temperature\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display Part (a) information\n",
        "print(\"Part (a): Temperature Statistics\")\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display mean temperature and standard deviation rounded to two decimal places\n",
        "print(f\"Mean Temperature: {mean_temp:.2f}\")\n",
        "print(f\"Standard Deviation of Temperature: {std_temp:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VlLesud9bQUi",
        "outputId": "eb2dea5a-aa2f-4bf4-bc26-706dceab0f7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Part (a): Temperature Statistics\n",
            "======================================================================\n",
            "Mean Temperature: 210.97\n",
            "Standard Deviation of Temperature: 16.80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (b) =====================\n",
        "\n",
        "# Define conditions for categorizing the temperature values\n",
        "# Three categories based on the \"Temperature\" column: low, medium, and high\n",
        "conditions = [\n",
        "    (df['Temperature'] < 200),                          # Temperature below 200 is 'low'\n",
        "    (df['Temperature'] >= 200) & (df['Temperature'] <= 220), # Temperature between 200 and 220 (inclusive) is 'medium'\n",
        "    (df['Temperature'] > 220)                            # Temperature above 220 is 'high'\n",
        "]\n",
        "\n",
        "# Define the choices corresponding to the conditions\n",
        "choices = ['low', 'medium', 'high']\n"
      ],
      "metadata": {
        "id": "Sw5idMaEbcgJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a new column \"TempCategory\" in the DataFrame based on the conditions\n",
        "# Use np.select() to assign the appropriate category for each row\n",
        "df['TempCategory'] = np.select(conditions, choices, default='unknown')\n",
        "\n",
        "# Calculate the frequency (count) of each category in the \"TempCategory\" column\n",
        "frequency = df['TempCategory'].value_counts()\n",
        "\n",
        "# Calculate the probability of each category (frequency divided by total number of rows)\n",
        "probability = frequency / len(df)\n"
      ],
      "metadata": {
        "id": "A3oWsI4Hbdq2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the results for Part (b)\n",
        "# Displaying the frequency and probability of temperature categories\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display Part (b) information\n",
        "print(\"Part (b): Temperature Categories\")\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display frequency of each category\n",
        "print(\"Frequency of Temperature Categories:\")\n",
        "print(frequency)\n",
        "\n",
        "# Display probability table for each category\n",
        "print(\"\\nProbability Table for Temperature Categories:\")\n",
        "print(probability)\n",
        "\n",
        "# Save the DataFrame with the new \"TempCategory\" column to a new CSV file\n",
        "df.to_csv(\"data_with_temp_category.csv\", index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WoTwc4h4be-i",
        "outputId": "925c604c-111f-487e-87e5-ffd4a3db8f49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Part (b): Temperature Categories\n",
            "======================================================================\n",
            "Frequency of Temperature Categories:\n",
            "TempCategory\n",
            "medium    12\n",
            "low       10\n",
            "high       8\n",
            "Name: count, dtype: int64\n",
            "\n",
            "Probability Table for Temperature Categories:\n",
            "TempCategory\n",
            "medium    0.400000\n",
            "low       0.333333\n",
            "high      0.266667\n",
            "Name: count, dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Importing Required Libraries =====================\n",
        "\n",
        "# Importing LinearRegression for model training and mean_squared_error for evaluating the model\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from sklearn.metrics import mean_squared_error\n"
      ],
      "metadata": {
        "id": "P6yC46p-bfiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (c) =====================\n",
        "\n",
        "# Convert 'FlowRate' from categorical text (low, high) to numeric values (0, 1)\n",
        "df['FlowRate_num'] = df['FlowRate'].str.lower().map({'low': 0, 'high': 1})\n",
        "\n",
        "# Convert 'Robustness' from categorical text (weak, moderate, strong) to numeric values (0, 1, 2)\n",
        "df['Robustness_num'] = df['Robustness'].str.lower().map({'weak': 0, 'moderate': 1, 'strong': 2})\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Display information for Part (c)\n",
        "print(\"Part (c): Linear Regression Model\")\n",
        "\n",
        "# Print separator for readability\n",
        "print(\"=\" * 70)\n",
        "\n",
        "# Check for missing values in relevant columns\n",
        "print(\"Missing values in 'FlowRate_num':\", df['FlowRate_num'].isnull().sum())\n",
        "print(\"Missing values in 'Robustness_num':\", df['Robustness_num'].isnull().sum())\n",
        "print(\"Missing values in 'TempCategory':\", df['TempCategory'].isnull().sum())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ga-MYoCjbkpG",
        "outputId": "50a82357-ccd3-4ee1-f10e-866e76332db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "======================================================================\n",
            "Part (c): Linear Regression Model\n",
            "======================================================================\n",
            "Missing values in 'FlowRate_num': 0\n",
            "Missing values in 'Robustness_num': 0\n",
            "Missing values in 'TempCategory': 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Create dummy variables for 'TempCategory', excluding the first category to avoid multicollinearity\n",
        "temp_dummies = pd.get_dummies(df['TempCategory'], drop_first=True)\n",
        "\n",
        "# Prepare feature matrix 'X' (independent variables)\n",
        "# Combine 'FlowRate_num' and the dummy variables for 'TempCategory'\n",
        "X = pd.concat([df[['FlowRate_num']], temp_dummies], axis=1)\n",
        "\n",
        "# Prepare target variable 'y' (dependent variable)\n",
        "y = df['Robustness_num']\n",
        "\n",
        "# Remove rows with missing values in either X or y for model training\n",
        "df_nonnull = pd.concat([X, y], axis=1).dropna()\n",
        "\n",
        "# Split X and y for non-null rows\n",
        "X_nonnull = df_nonnull.drop('Robustness_num', axis=1)\n",
        "y_nonnull = df_nonnull['Robustness_num']\n",
        "\n",
        "# Check if there are valid rows for training\n",
        "if len(df_nonnull) == 0:\n",
        "    print(\"\\nNo valid rows after dropping missing values. Cannot train the model.\")\n",
        "else:\n",
        "    # Train the Linear Regression model\n",
        "    model = LinearRegression()\n",
        "    model.fit(X_nonnull, y_nonnull)\n",
        "\n",
        "    # Make predictions using the trained model\n",
        "    y_pred = model.predict(X_nonnull)\n",
        "\n",
        "    # Calculate the Mean Squared Error (MSE) of the model\n",
        "    mse = mean_squared_error(y_nonnull, y_pred)\n",
        "\n",
        "    # Display the model results\n",
        "    print(\"\\nLinear Regression Model Results\")\n",
        "    print(\"-\" * 70)\n",
        "    print(f\"Intercept: {model.intercept_:.4f}\")\n",
        "\n",
        "    # Display coefficients for each feature\n",
        "    for col_name, coef_value in zip(X_nonnull.columns, model.coef_):\n",
        "        print(f\"Coefficient for {col_name}: {coef_value:.4f}\")\n",
        "\n",
        "    # Display Mean Squared Error\n",
        "    print(f\"\\nMean Squared Error: {mse:.4f}\")\n",
        "\n",
        "    # Print separator for readability\n",
        "    print(\"=\" * 70)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OtaNIVuVbl-D",
        "outputId": "cb0656d6-009f-4128-afde-6fad1a0087da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Linear Regression Model Results\n",
            "----------------------------------------------------------------------\n",
            "Intercept: 2.0786\n",
            "Coefficient for FlowRate_num: -0.5257\n",
            "Coefficient for low: -1.6157\n",
            "Coefficient for medium: -0.4429\n",
            "\n",
            "Mean Squared Error: 0.1334\n",
            "======================================================================\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 2"
      ],
      "metadata": {
        "id": "A_RX2t-YeUXs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Importing Required Library =====================\n",
        "\n",
        "# Import pandas for data manipulation\n",
        "import pandas as pd\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/data_with_temp_category.csv\")\n"
      ],
      "metadata": {
        "id": "gehrwJBjbnli"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (a) =====================\n",
        "\n",
        "# Calculate the total number of rows in the DataFrame\n",
        "total_count = len(df)\n",
        "\n",
        "# Count the occurrences of \"FlowRate\" being \"fast\" (case insensitive)\n",
        "count_fast = (df[\"FlowRate\"].str.lower() == \"fast\").sum()  # or \"high\"\n",
        "\n",
        "# Calculate the probability P(FlowRate = fast)\n",
        "p_flow_fast = count_fast / total_count\n",
        "\n",
        "# Print the result for part (a)\n",
        "print(\"(a) P(FlowRate=fast) =\", p_flow_fast)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "McjVqbXcbs93",
        "outputId": "53c231ad-f4b2-43bb-9c17-c8ce020e72dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(a) P(FlowRate=fast) = 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (b) =====================\n",
        "\n",
        "# (b1) Calculate the probability distribution for the \"FlowRate\" values\n",
        "p_flow = df[\"FlowRate\"].value_counts(normalize=True)\n",
        "print(\"\\n(b1) Probability distribution for FlowRate:\")\n",
        "print(p_flow)\n",
        "\n",
        "# (b2) Calculate the conditional probability P(Robustness | Temperature, FlowRate)\n",
        "counts = df.groupby([\"TempCategory\", \"FlowRate\", \"Robustness\"]).size()\n",
        "cond_probs = counts.groupby(level=[0, 1]).apply(lambda x: x / x.sum())\n",
        "print(\"\\n(b2) P(Robustness | Temperature, FlowRate):\")\n",
        "print(cond_probs)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1BFMF_EgbuJy",
        "outputId": "e13d6df7-20d3-424e-dde2-7573be439972"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(b1) Probability distribution for FlowRate:\n",
            "FlowRate\n",
            "Low     0.5\n",
            "High    0.5\n",
            "Name: proportion, dtype: float64\n",
            "\n",
            "(b2) P(Robustness | Temperature, FlowRate):\n",
            "TempCategory  FlowRate  TempCategory  FlowRate  Robustness\n",
            "high          High      high          High      Moderate      0.400000\n",
            "                                                Strong        0.600000\n",
            "              Low       high          Low       Strong        1.000000\n",
            "low           High      low           High      Weak          1.000000\n",
            "              Low       low           Low       Moderate      0.400000\n",
            "                                                Weak          0.600000\n",
            "medium        High      medium        High      Moderate      1.000000\n",
            "              Low       medium        Low       Moderate      0.285714\n",
            "                                                Strong        0.714286\n",
            "dtype: float64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (c) =====================\n",
        "\n",
        "# (c) Calculate probabilities for the \"Robustness\" categories\n",
        "robust_counts = df[\"Robustness\"].value_counts(normalize=True)\n",
        "p_W = robust_counts.get(\"Weak\", 0)\n",
        "p_M = robust_counts.get(\"Moderate\", 0)\n",
        "p_S = robust_counts.get(\"Strong\", 0)\n",
        "\n",
        "# Calculate P(PassesQA)\n",
        "p_passQA = 0.3 * p_W + 0.6 * p_M + 0.9 * p_S\n",
        "\n",
        "# Calculate conditional probabilities P(Robustness | PassesQA)\n",
        "p_W_pass = (0.3 * p_W) / p_passQA\n",
        "p_M_pass = (0.6 * p_M) / p_passQA\n",
        "p_S_pass = (0.9 * p_S) / p_passQA\n",
        "\n",
        "# Calculate the probability of breaks given passesQA\n",
        "p_break_passQA = 0.5 * p_W_pass + 0.1 * p_M_pass + 0.01 * p_S_pass\n",
        "\n",
        "# Print the result for part (c)\n",
        "print(\"\\n(c) P(Breaks | PassesQA) =\", p_break_passQA)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hMm--1YZbwKC",
        "outputId": "cc0e86b3-ebc2-43f5-a434-a2397c3e2513"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(c) P(Breaks | PassesQA) = 0.10365079365079366\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (d) =====================\n",
        "\n",
        "# (d) Calculate the conditional probability P(Weak | Breaks, PassesQA)\n",
        "p_weak_given_break_pass = (0.5 * p_W_pass) / p_break_passQA\n",
        "print(\"\\n(d) P(Weak | Breaks, PassesQA) =\", p_weak_given_break_pass)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3vnpr5WVbxRW",
        "outputId": "4f1a4983-79be-44be-900e-2eab159ff0e3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "(d) P(Weak | Breaks, PassesQA) = 0.6125574272588056\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install pyagrum"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "peTUnO1pbyFk",
        "outputId": "e6a46a52-5804-4961-ac1e-ce9eeb960187"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyagrum in /usr/local/lib/python3.11/dist-packages (1.17.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from pyagrum) (1.26.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from pyagrum) (3.10.0)\n",
            "Requirement already satisfied: pydot in /usr/local/lib/python3.11/dist-packages (from pyagrum) (3.0.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->pyagrum) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->pyagrum) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 3"
      ],
      "metadata": {
        "id": "LQvloFNHeYao"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Importing Required Libraries =====================\n",
        "# Importing pyAgrum library for creating and manipulating Bayesian Networks\n",
        "import pyAgrum as gum\n",
        "# Importing pyAgrum notebook utility for visualization\n",
        "import pyAgrum.lib.notebook as gnb\n"
      ],
      "metadata": {
        "id": "OyCqYdpzb1L2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Part (a) - Defining the Bayesian Network =====================\n",
        "\n",
        "# Create a new Bayesian Network with the name \"LisaScenario\"\n",
        "bn = gum.BayesNet(\"LisaScenario\")\n",
        "\n",
        "# Define the \"TemperatureCategory\" variable with 3 possible labels: Low, Medium, High\n",
        "temp_var = gum.LabelizedVariable(\"TemperatureCategory\", \"Temperature category\", 0)\n",
        "temp_var.addLabel(\"Low\")\n",
        "temp_var.addLabel(\"Medium\")\n",
        "temp_var.addLabel(\"High\")\n",
        "temp_id = bn.add(temp_var)\n",
        "\n",
        "# Define the \"FlowRate\" variable with 2 possible labels: Low, High\n",
        "flow_var = gum.LabelizedVariable(\"FlowRate\", \"Flow rate\", 0)\n",
        "flow_var.addLabel(\"Low\")\n",
        "flow_var.addLabel(\"High\")\n",
        "flow_id = bn.add(flow_var)\n",
        "\n",
        "# Define the \"Robustness\" variable with 3 possible labels: Weak, Moderate, Strong\n",
        "rob_var = gum.LabelizedVariable(\"Robustness\", \"Robustness level\", 0)\n",
        "rob_var.addLabel(\"Weak\")\n",
        "rob_var.addLabel(\"Moderate\")\n",
        "rob_var.addLabel(\"Strong\")\n",
        "rob_id = bn.add(rob_var)\n",
        "\n",
        "# Define the \"QA\" variable with 2 possible labels: Fail, Pass\n",
        "qa_var = gum.LabelizedVariable(\"QA\", \"QA outcome\", 0)\n",
        "qa_var.addLabel(\"Fail\")\n",
        "qa_var.addLabel(\"Pass\")\n",
        "qa_id = bn.add(qa_var)\n",
        "\n",
        "# Define the \"Breaks\" variable with 2 possible labels: False, True\n",
        "br_var = gum.LabelizedVariable(\"Breaks\", \"Product breaks?\", 0)\n",
        "br_var.addLabel(\"False\")\n",
        "br_var.addLabel(\"True\")\n",
        "br_id = bn.add(br_var)\n"
      ],
      "metadata": {
        "id": "2yXw8xiqb8O4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ===================== Adding Arcs (Relationships) Between Variables =====================\n",
        "\n",
        "# Adding directed edges (arcs) between the variables to define the dependencies\n",
        "\n",
        "# \"TemperatureCategory\" influences \"Robustness\"\n",
        "bn.addArc(temp_id, rob_id)\n",
        "\n",
        "# \"FlowRate\" influences \"Robustness\"\n",
        "bn.addArc(flow_id, rob_id)\n",
        "\n",
        "# \"Robustness\" influences both \"QA\" and \"Breaks\"\n",
        "bn.addArc(rob_id, qa_id)\n",
        "bn.addArc(rob_id, br_id)\n",
        "\n",
        "# \"QA\" influences \"Breaks\"\n",
        "bn.addArc(qa_id, br_id)\n",
        "\n",
        "# Visualize the Bayesian Network\n",
        "gnb.showBN(bn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 368
        },
        "id": "BEmubhCnb9gX",
        "outputId": "30fdb394-fbe4-4246-e7a5-afdb89e515b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"292pt\" height=\"260pt\" viewBox=\"0.00 0.00 291.59 260.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 256)\">\n<title>G</title>\n<!-- TemperatureCategory -->\n<g id=\"node1\" class=\"node\">\n<title>TemperatureCategory</title>\n<g id=\"a_node1\"><a xlink:title=\"(0) TemperatureCategory\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"87.74\" cy=\"-234\" rx=\"87.99\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"87.74\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">TemperatureCategory</text>\n</a>\n</g>\n</g>\n<!-- Robustness -->\n<g id=\"node4\" class=\"node\">\n<title>Robustness</title>\n<g id=\"a_node4\"><a xlink:title=\"(2) Robustness\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"162.74\" cy=\"-162\" rx=\"50.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"162.74\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Robustness</text>\n</a>\n</g>\n</g>\n<!-- TemperatureCategory&#45;&gt;Robustness -->\n<g id=\"edge5\" class=\"edge\">\n<title>TemperatureCategory-&gt;Robustness</title>\n<g id=\"a_edge5\"><a xlink:title=\"0 → 2\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M105.9,-216.05C115.6,-207 127.67,-195.73 138.19,-185.91\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"140.6,-188.45 145.53,-179.07 135.83,-183.33 140.6,-188.45\"/>\n</a>\n</g>\n</g>\n<!-- QA -->\n<g id=\"node2\" class=\"node\">\n<title>QA</title>\n<g id=\"a_node2\"><a xlink:title=\"(3) QA\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"135.74\" cy=\"-90\" rx=\"27\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"135.74\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">QA</text>\n</a>\n</g>\n</g>\n<!-- Breaks -->\n<g id=\"node3\" class=\"node\">\n<title>Breaks</title>\n<g id=\"a_node3\"><a xlink:title=\"(4) Breaks\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"162.74\" cy=\"-18\" rx=\"35.19\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"162.74\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Breaks</text>\n</a>\n</g>\n</g>\n<!-- QA&#45;&gt;Breaks -->\n<g id=\"edge3\" class=\"edge\">\n<title>QA-&gt;Breaks</title>\n<g id=\"a_edge3\"><a xlink:title=\"3 → 4\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M142.14,-72.41C145.26,-64.34 149.08,-54.43 152.58,-45.35\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"155.87,-46.55 156.2,-35.96 149.34,-44.03 155.87,-46.55\"/>\n</a>\n</g>\n</g>\n<!-- Robustness&#45;&gt;QA -->\n<g id=\"edge4\" class=\"edge\">\n<title>Robustness-&gt;QA</title>\n<g id=\"a_edge4\"><a xlink:title=\"2 → 3\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M156.21,-144.05C153.12,-136.06 149.37,-126.33 145.92,-117.4\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"149.08,-115.86 142.22,-107.79 142.55,-118.38 149.08,-115.86\"/>\n</a>\n</g>\n</g>\n<!-- Robustness&#45;&gt;Breaks -->\n<g id=\"edge1\" class=\"edge\">\n<title>Robustness-&gt;Breaks</title>\n<g id=\"a_edge1\"><a xlink:title=\"2 → 4\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M166.4,-143.91C168.42,-133.57 170.72,-120.09 171.74,-108 173.09,-92.06 173.09,-87.94 171.74,-72 171.03,-63.5 169.67,-54.31 168.23,-46.01\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"171.66,-45.29 166.4,-36.09 164.77,-46.56 171.66,-45.29\"/>\n</a>\n</g>\n</g>\n<!-- FlowRate -->\n<g id=\"node5\" class=\"node\">\n<title>FlowRate</title>\n<g id=\"a_node5\"><a xlink:title=\"(1) FlowRate\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"238.74\" cy=\"-234\" rx=\"44.69\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"238.74\" y=\"-230.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">FlowRate</text>\n</a>\n</g>\n</g>\n<!-- FlowRate&#45;&gt;Robustness -->\n<g id=\"edge2\" class=\"edge\">\n<title>FlowRate-&gt;Robustness</title>\n<g id=\"a_edge2\"><a xlink:title=\"1 → 2\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M221.5,-217.12C211.46,-207.87 198.64,-196.07 187.54,-185.84\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"189.91,-183.26 180.18,-179.06 185.17,-188.41 189.91,-183.26\"/>\n</a>\n</g>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyAgrum as gum\n",
        "import pyAgrum.lib.notebook as gnb\n",
        "import pandas as pd\n",
        "#===================== (b) =====================\n",
        "data = pd.read_csv(\"/content/data_with_temp_category.csv\")\n",
        "\n",
        "bn = gum.BayesNet(\"LisaScenario\")\n",
        "\n",
        "\n",
        "temp_var = gum.LabelizedVariable(\"TempCategory\", \"Temperature category\", 0)\n",
        "\n",
        "temp_var.addLabel(\"low\")\n",
        "\n",
        "temp_var.addLabel(\"medium\")\n",
        "\n",
        "temp_var.addLabel(\"high\")\n",
        "\n",
        "temp_id = bn.add(temp_var)\n",
        "\n",
        "flow_var = gum.LabelizedVariable(\"FlowRate\", \"Flow rate\", 0)\n",
        "\n",
        "flow_var.addLabel(\"Low\")\n",
        "\n",
        "flow_var.addLabel(\"High\")\n",
        "\n",
        "flow_id = bn.add(flow_var)\n",
        "\n",
        "rob_var = gum.LabelizedVariable(\"Robustness\", \"Robustness level\", 0)\n",
        "\n",
        "rob_var.addLabel(\"Weak\")\n",
        "\n",
        "rob_var.addLabel(\"Moderate\")\n",
        "\n",
        "rob_var.addLabel(\"Strong\")\n",
        "\n",
        "\n",
        "rob_id = bn.add(rob_var)\n",
        "\n",
        "qa_var = gum.LabelizedVariable(\"QA\", \"QA outcome\", 0)\n",
        "\n",
        "qa_var.addLabel(\"Fail\")\n",
        "\n",
        "qa_var.addLabel(\"Pass\")\n",
        "\n",
        "qa_id = bn.add(qa_var)\n",
        "\n",
        "br_var = gum.LabelizedVariable(\"Breaks\", \"Product breaks?\", 0)\n",
        "\n",
        "br_var.addLabel(\"False\")\n",
        "\n",
        "br_var.addLabel(\"True\")\n",
        "\n",
        "br_id = bn.add(br_var)\n",
        "\n",
        "bn.addArc(temp_id, rob_id)\n",
        "\n",
        "bn.addArc(flow_id, rob_id)\n",
        "\n",
        "bn.addArc(rob_id, qa_id)\n",
        "\n",
        "bn.addArc(rob_id, br_id)\n",
        "\n",
        "bn.addArc(qa_id, br_id)\n",
        "\n",
        "temp_counts = data[\"TempCategory\"].value_counts(normalize=True)\n",
        "\n",
        "bn.cpt(temp_id)[0] = temp_counts.get(\"low\", 0)\n",
        "\n",
        "bn.cpt(temp_id)[1] = temp_counts.get(\"medium\", 0)\n",
        "\n",
        "bn.cpt(temp_id)[2] = temp_counts.get(\"high\", 0)\n",
        "\n",
        "flow_counts = data[\"FlowRate\"].value_counts(normalize=True)\n",
        "\n",
        "bn.cpt(flow_id)[0] = flow_counts.get(\"Low\", 0)\n",
        "\n",
        "bn.cpt(flow_id)[1] = flow_counts.get(\"High\", 0)\n",
        "\n",
        "robustness_counts = data.groupby([\"TempCategory\", \"FlowRate\", \"Robustness\"]).size().unstack(fill_value=0)\n",
        "\n",
        "robustness_probs = robustness_counts.div(robustness_counts.sum(axis=1), axis=0)\n",
        "\n",
        "temp_map = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
        "\n",
        "flow_map = {\"Low\": 0, \"High\": 1}\n",
        "\n",
        "robustness_map = {\"Weak\": 0, \"Moderate\": 1, \"Strong\": 2}\n",
        "\n",
        "for temp, temp_idx in temp_map.items():\n",
        "\n",
        "    for flow, flow_idx in flow_map.items():\n",
        "        if (temp, flow) in robustness_probs.index:\n",
        "            bn.cpt(rob_id)[{\"TempCategory\": temp_idx, \"FlowRate\": flow_idx}] = [\n",
        "\n",
        "                robustness_probs.loc[(temp, flow), \"Weak\"],\n",
        "                robustness_probs.loc[(temp, flow), \"Moderate\"],\n",
        "                robustness_probs.loc[(temp, flow), \"Strong\"],\n",
        "            ]\n",
        "\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Weak\"]}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Moderate\"]}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Strong\"]}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Weak\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Weak\"], \"QA\": 1}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Moderate\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Moderate\"], \"QA\": 1}] = [0.5, 0.5]\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Strong\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "\n",
        "\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Strong\"], \"QA\": 1}] = [0.5, 0.5]\n",
        "\n",
        "ie = gum.LazyPropagation(bn)\n",
        "\n",
        "ie.setEvidence({\"FlowRate\": flow_map[\"High\"], \"Breaks\": 1})\n",
        "\n",
        "ie.makeInference()\n",
        "\n",
        "result = ie.posterior(rob_id)\n",
        "\n",
        "print(\"Probability that the product was 'Strongly robust' given high flow rate and it broke:\")\n",
        "\n",
        "print(result[robustness_map[\"Strong\"]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P4zOBPv3hHeL",
        "outputId": "27b5d681-7a40-4793-eaac-e6324c662c15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability that the product was 'Strongly robust' given high flow rate and it broke:\n",
            "0.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pyAgrum as gum\n",
        "import pyAgrum.lib.notebook as gnb\n",
        "import pandas as pd\n",
        "\n",
        "#===================== (c) =====================\n",
        "\n",
        "# Read the data from the CSV file\n",
        "data = pd.read_csv(\"/content/data_with_temp_category.csv\")\n",
        "\n",
        "# Initialize the Bayesian Network\n",
        "bn = gum.BayesNet(\"LisaScenario\")\n"
      ],
      "metadata": {
        "id": "uEe0H2IbftZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Define the temperature category variable and its labels\n",
        "temp_var = gum.LabelizedVariable(\"TempCategory\", \"Temperature category\", 0)\n",
        "temp_var.addLabel(\"low\")\n",
        "temp_var.addLabel(\"medium\")\n",
        "temp_var.addLabel(\"high\")\n",
        "\n",
        "# Add temperature node to the network\n",
        "temp_id = bn.add(temp_var)\n",
        "\n",
        "# Define flow rate variable and its labels\n",
        "flow_var = gum.LabelizedVariable(\"FlowRate\", \"Flow rate\", 0)\n",
        "flow_var.addLabel(\"Low\")\n",
        "flow_var.addLabel(\"High\")\n",
        "\n",
        "# Add flow rate node to the network\n",
        "flow_id = bn.add(flow_var)\n",
        "\n",
        "# Define robustness level variable and its labels\n",
        "rob_var = gum.LabelizedVariable(\"Robustness\", \"Robustness level\", 0)\n",
        "rob_var.addLabel(\"Weak\")\n",
        "rob_var.addLabel(\"Moderate\")\n",
        "rob_var.addLabel(\"Strong\")\n",
        "\n",
        "# Add robustness node to the network\n",
        "rob_id = bn.add(rob_var)\n",
        "\n",
        "# Define QA outcome variable and its labels\n",
        "qa_var = gum.LabelizedVariable(\"QA\", \"QA outcome\", 0)\n",
        "qa_var.addLabel(\"Fail\")\n",
        "qa_var.addLabel(\"Pass\")\n",
        "\n",
        "# Add QA node to the network\n",
        "qa_id = bn.add(qa_var)\n",
        "\n",
        "# Define product breaks variable and its labels\n",
        "br_var = gum.LabelizedVariable(\"Breaks\", \"Product breaks?\", 0)\n",
        "br_var.addLabel(\"False\")\n",
        "br_var.addLabel(\"True\")\n",
        "\n",
        "# Add breaks node to the network\n",
        "br_id = bn.add(br_var)\n"
      ],
      "metadata": {
        "id": "_4luQ8hjfvUr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Add arcs (dependencies) between nodes\n",
        "bn.addArc(temp_id, rob_id)\n",
        "bn.addArc(flow_id, rob_id)\n",
        "bn.addArc(rob_id, qa_id)\n",
        "bn.addArc(rob_id, br_id)\n",
        "bn.addArc(qa_id, br_id)\n",
        "\n",
        "# Set CPT for TempCategory based on data\n",
        "temp_counts = data[\"TempCategory\"].value_counts(normalize=True)\n",
        "bn.cpt(temp_id)[0] = temp_counts.get(\"low\", 0)\n",
        "bn.cpt(temp_id)[1] = temp_counts.get(\"medium\", 0)\n",
        "bn.cpt(temp_id)[2] = temp_counts.get(\"high\", 0)\n",
        "\n",
        "# Set CPT for FlowRate based on data\n",
        "flow_counts = data[\"FlowRate\"].value_counts(normalize=True)\n",
        "bn.cpt(flow_id)[0] = flow_counts.get(\"Low\", 0)\n",
        "bn.cpt(flow_id)[1] = flow_counts.get(\"High\", 0)\n",
        "\n",
        "# Set CPT for Robustness based on data\n",
        "robustness_counts = data.groupby([\"TempCategory\", \"FlowRate\", \"Robustness\"]).size().unstack(fill_value=0)\n",
        "robustness_probs = robustness_counts.div(robustness_counts.sum(axis=1), axis=0)\n",
        "\n",
        "# Map labels to indices for convenience\n",
        "temp_map = {\"low\": 0, \"medium\": 1, \"high\": 2}\n",
        "flow_map = {\"Low\": 0, \"High\": 1}\n",
        "robustness_map = {\"Weak\": 0, \"Moderate\": 1, \"Strong\": 2}\n",
        "\n",
        "# Populate Robustness CPT using the probabilities calculated\n",
        "for temp, temp_idx in temp_map.items():\n",
        "    for flow, flow_idx in flow_map.items():\n",
        "        if (temp, flow) in robustness_probs.index:\n",
        "            bn.cpt(rob_id)[{\"TempCategory\": temp_idx, \"FlowRate\": flow_idx}] = [\n",
        "                robustness_probs.loc[(temp, flow), \"Weak\"],\n",
        "                robustness_probs.loc[(temp, flow), \"Moderate\"],\n",
        "                robustness_probs.loc[(temp, flow), \"Strong\"],\n",
        "            ]\n"
      ],
      "metadata": {
        "id": "eGjIMmKsfw2y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Set CPT for QA based on Robustness\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Weak\"]}] = [0.5, 0.5]\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Moderate\"]}] = [0.5, 0.5]\n",
        "bn.cpt(qa_id)[{\"Robustness\": robustness_map[\"Strong\"]}] = [0.5, 0.5]\n",
        "\n",
        "# Set CPT for Breaks based on Robustness and QA outcome\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Weak\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Weak\"], \"QA\": 1}] = [0.5, 0.5]\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Moderate\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Moderate\"], \"QA\": 1}] = [0.5, 0.5]\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Strong\"], \"QA\": 0}] = [0.5, 0.5]\n",
        "bn.cpt(br_id)[{\"Robustness\": robustness_map[\"Strong\"], \"QA\": 1}] = [0.5, 0.5]\n"
      ],
      "metadata": {
        "id": "BCSwfK7Vfz4v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Perform inference for low temperature scenario\n",
        "ie_low = gum.LazyPropagation(bn)\n",
        "ie_low.setEvidence({\"TempCategory\": temp_map[\"low\"]})\n",
        "ie_low.makeInference()\n",
        "p_break_low = ie_low.posterior(br_id)[1]\n",
        "\n",
        "# Perform inference for high temperature scenario\n",
        "ie_high = gum.LazyPropagation(bn)\n",
        "ie_high.setEvidence({\"TempCategory\": temp_map[\"high\"]})\n",
        "ie_high.makeInference()\n",
        "p_break_high = ie_high.posterior(br_id)[1]\n"
      ],
      "metadata": {
        "id": "KHKevkyJf2RY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculate the relative risk between low and high temperature\n",
        "relative_risk = p_break_low / p_break_high\n",
        "\n",
        "# Print results for probabilities and relative risk\n",
        "print(f\"Probability of breaking at low temperature: {p_break_low:.4f}\")\n",
        "print(f\"Probability of breaking at high temperature: {p_break_high:.4f}\")\n",
        "print(f\"Relative risk (low vs. high temperature): {relative_risk:.4f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3h5xOSJ6f3Xu",
        "outputId": "66212baf-6f6e-4474-9c94-70a71176bcef"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of breaking at low temperature: 0.5000\n",
            "Probability of breaking at high temperature: 0.5000\n",
            "Relative risk (low vs. high temperature): 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 4"
      ],
      "metadata": {
        "id": "HKRdvET6c3jv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing the pyAgrum library for influence diagram creation and visualization.\n",
        "import pyAgrum as gum\n",
        "# Importing the pyAgrum notebook tools for easy visualization of the influence diagram.\n",
        "import pyAgrum.lib.notebook as gnb\n"
      ],
      "metadata": {
        "id": "_JgrR32Mc2lQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, let's create an empty influence diagram object.\n",
        "influence_diagram = gum.InfluenceDiagram()\n"
      ],
      "metadata": {
        "id": "tNoWgHX9c7c9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a variable for the \"Quality Assurance Decision\".\n",
        "qa_var = gum.LabelizedVariable(\"QA\", \"Quality Assurance Decision\", 0)\n",
        "\n",
        "# Adding possible labels for the QA decision: \"Keep\" and \"Drop\".\n",
        "qa_var.addLabel(\"Keep\")\n",
        "qa_var.addLabel(\"Drop\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FD3vGCvzc_k-",
        "outputId": "7fc8ed12-281c-4e2f-9fe8-78be1cb193ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pyAgrum.LabelizedVariable@0x32959e0) QA:Labelized({Keep|Drop})"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a variable for the \"Robustness Level\".\n",
        "robustness_var = gum.LabelizedVariable(\"Robustness\", \"Robustness Level\", 0)\n",
        "\n",
        "# Adding possible labels for the Robustness: \"Weak\", \"Moderate\", \"Strong\".\n",
        "robustness_var.addLabel(\"Weak\")\n",
        "robustness_var.addLabel(\"Moderate\")\n",
        "robustness_var.addLabel(\"Strong\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yrsZuxIFdAAc",
        "outputId": "708c4b17-4bf8-49fb-fbb5-7a2a559a3a86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pyAgrum.LabelizedVariable@0x3b54080) Robustness:Labelized({Weak|Moderate|Strong})"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining a variable for the \"Product Breaks?\".\n",
        "breaks_var = gum.LabelizedVariable(\"Breaks\", \"Product Breaks?\", 0)\n",
        "\n",
        "# Adding possible labels for the Breaks: \"False\" and \"True\".\n",
        "breaks_var.addLabel(\"False\")\n",
        "breaks_var.addLabel(\"True\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce8cLHWOdBaG",
        "outputId": "42ecdbe9-bc69-4181-e729-834aaa3e2c03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(pyAgrum.LabelizedVariable@0x391f700) Breaks:Labelized({False|True})"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding the QA decision variable as a decision node in the influence diagram.\n",
        "qa_decision = influence_diagram.addDecisionNode(qa_var)\n",
        "\n",
        "# Adding the Robustness variable as a chance node in the influence diagram.\n",
        "robustness = influence_diagram.addChanceNode(robustness_var)\n",
        "\n",
        "# Adding the Breaks variable as a chance node in the influence diagram.\n",
        "breaks = influence_diagram.addChanceNode(breaks_var)\n",
        "\n",
        "# Adding a utility node to the influence diagram for the final outcome.\n",
        "utility = influence_diagram.addUtilityNode(\"Utility\")\n"
      ],
      "metadata": {
        "id": "mHvrYlu9dDG_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Adding an arc from the QA decision to the Robustness node.\n",
        "influence_diagram.addArc(qa_decision, robustness)\n",
        "\n",
        "# Adding an arc from the Robustness node to the Breaks node.\n",
        "influence_diagram.addArc(robustness, breaks)\n",
        "\n",
        "# Adding an arc from the QA decision to the Utility node.\n",
        "influence_diagram.addArc(qa_decision, utility)\n",
        "\n",
        "# Adding an arc from the Breaks node to the Utility node.\n",
        "influence_diagram.addArc(breaks, utility)\n"
      ],
      "metadata": {
        "id": "h4N8zGL7dEfH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Finally, let's visualize the influence diagram to see the structure.\n",
        "gnb.showInfluenceDiagram(influence_diagram)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 387
        },
        "id": "MOWoWDxBdFh9",
        "outputId": "4d203010-41b5-40e5-a1a3-df5ec9c1ff98"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"144pt\" height=\"274pt\" viewBox=\"0.00 0.00 143.56 274.38\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 270.38)\">\n<title>G</title>\n<!-- Robustness -->\n<g id=\"node1\" class=\"node\">\n<title>Robustness</title>\n<ellipse fill=\"#808080\" stroke=\"#4a4a4a\" cx=\"53.74\" cy=\"-180.88\" rx=\"53.98\" ry=\"20.51\"/>\n<text text-anchor=\"middle\" x=\"53.74\" y=\"-177.18\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#4a4a4a\">Robustness</text>\n</g>\n<!-- Breaks -->\n<g id=\"node2\" class=\"node\">\n<title>Breaks</title>\n<ellipse fill=\"#808080\" stroke=\"#4a4a4a\" cx=\"62.74\" cy=\"-103.86\" rx=\"36.54\" ry=\"20.51\"/>\n<text text-anchor=\"middle\" x=\"62.74\" y=\"-100.16\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#4a4a4a\">Breaks</text>\n</g>\n<!-- Robustness&#45;&gt;Breaks -->\n<g id=\"edge3\" class=\"edge\">\n<title>Robustness-&gt;Breaks</title>\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M56.1,-160.17C57.05,-152.33 58.15,-143.14 59.18,-134.53\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"62.67,-134.79 60.39,-124.44 55.72,-133.95 62.67,-134.79\"/>\n</g>\n<!-- Utility -->\n<g id=\"node4\" class=\"node\">\n<title>Utility</title>\n<polygon fill=\"#50508a\" stroke=\"#4a4a4a\" points=\"135.39,-23.68 115.07,-47.54 74.41,-47.54 54.09,-23.68 74.41,0.18 115.07,0.18 135.39,-23.68\"/>\n<text text-anchor=\"middle\" x=\"94.74\" y=\"-19.98\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#4a4a4a\">Utility</text>\n</g>\n<!-- Breaks&#45;&gt;Utility -->\n<g id=\"edge4\" class=\"edge\">\n<title>Breaks-&gt;Utility</title>\n<path fill=\"none\" stroke=\"#4a4a4a\" stroke-dasharray=\"5,2\" d=\"M70.65,-83.54C73.94,-75.5 77.85,-65.95 81.55,-56.91\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"84.9,-57.97 85.44,-47.39 78.42,-55.32 84.9,-57.97\"/>\n</g>\n<!-- QA -->\n<g id=\"node3\" class=\"node\">\n<title>QA</title>\n<polygon fill=\"#9a5050\" stroke=\"#4a4a4a\" points=\"121.74,-266.38 67.74,-266.38 67.74,-237.38 121.74,-237.38 121.74,-266.38\"/>\n<text text-anchor=\"middle\" x=\"94.74\" y=\"-248.18\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"#4a4a4a\">QA</text>\n</g>\n<!-- QA&#45;&gt;Robustness -->\n<g id=\"edge1\" class=\"edge\">\n<title>QA-&gt;Robustness</title>\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M86.64,-237.25C81.97,-229.39 75.93,-219.22 70.3,-209.74\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"73.2,-207.77 65.08,-200.97 67.18,-211.35 73.2,-207.77\"/>\n</g>\n<!-- QA&#45;&gt;Utility -->\n<g id=\"edge2\" class=\"edge\">\n<title>QA-&gt;Utility</title>\n<path fill=\"none\" stroke=\"#4a4a4a\" stroke-dasharray=\"5,2\" d=\"M102.74,-237.12C107.86,-227.47 114.05,-214.08 116.74,-201.38 127.28,-151.7 115.23,-93.01 105.25,-57.34\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"108.53,-56.1 102.37,-47.48 101.81,-58.06 108.53,-56.1\"/>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining constants for profit and loss.\n",
        "profit_if_sold = 2000  # Profit if the product is sold.\n",
        "loss_if_breaks = -10000  # Loss if the product breaks.\n",
        "\n",
        "# Defining the probability distributions for robustness with QA (keep) and without QA (drop).\n",
        "p_robustness_keep = {\n",
        "    \"Weak\": 0.1,\n",
        "    \"Moderate\": 0.3,\n",
        "    \"Strong\": 0.6\n",
        "}\n",
        "p_robustness_drop = {\n",
        "    \"Weak\": 0.5,\n",
        "    \"Moderate\": 0.3,\n",
        "    \"Strong\": 0.2\n",
        "}\n",
        "\n",
        "# Defining the probability of breaks for different robustness levels.\n",
        "p_breaks = {\n",
        "    \"Weak\": 0.8,\n",
        "    \"Moderate\": 0.3,\n",
        "    \"Strong\": 0.1\n",
        "}\n"
      ],
      "metadata": {
        "id": "_5k3quB6dWRu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating expected utility if Lisa keeps the QA process.\n",
        "expected_utility_keep = 0\n",
        "for robustness, p_rob in p_robustness_keep.items():\n",
        "    p_break = p_breaks[robustness]\n",
        "    expected_utility_keep += p_rob * (p_break * loss_if_breaks + (1 - p_break) * profit_if_sold)\n",
        "\n",
        "# Calculating expected utility if Lisa drops the QA process.\n",
        "expected_utility_drop = 0\n",
        "for robustness, p_rob in p_robustness_drop.items():\n",
        "    p_break = p_breaks[robustness]\n",
        "    expected_utility_drop += p_rob * (p_break * loss_if_breaks + (1 - p_break) * profit_if_sold)\n"
      ],
      "metadata": {
        "id": "zXv6YARddXkl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying expected utilities for both scenarios.\n",
        "print(f\"Expected utility if Lisa keeps QA: £{expected_utility_keep:.2f}\")\n",
        "print(f\"Expected utility if Lisa drops QA: £{expected_utility_drop:.2f}\")\n",
        "\n",
        "# Making the decision based on the calculated expected utilities.\n",
        "if expected_utility_keep > expected_utility_drop:\n",
        "    print(\"Lisa should keep the QA process.\")\n",
        "else:\n",
        "    print(\"Lisa should drop the QA process.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kQKDa_YqdY1w",
        "outputId": "4fdc24dc-89ac-4b6f-9610-35f704a35b07"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected utility if Lisa keeps QA: £-760.00\n",
            "Expected utility if Lisa drops QA: £-4120.00\n",
            "Lisa should keep the QA process.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the probability distributions for robustness with QA (keep) and without QA (drop) at low flow rate.\n",
        "p_robustness_keep_low_flow = {\n",
        "    \"Weak\": 0.05,\n",
        "    \"Moderate\": 0.25,\n",
        "    \"Strong\": 0.7\n",
        "}\n",
        "\n",
        "p_robustness_drop_low_flow = {\n",
        "    \"Weak\": 0.3,\n",
        "    \"Moderate\": 0.4,\n",
        "    \"Strong\": 0.3\n",
        "}\n"
      ],
      "metadata": {
        "id": "DK5ggQFKdd9u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating expected utility if Lisa keeps the QA process at low flow rate.\n",
        "expected_utility_keep_low_flow = 0\n",
        "for robustness, p_rob in p_robustness_keep_low_flow.items():\n",
        "    p_break = p_breaks[robustness]\n",
        "    expected_utility_keep_low_flow += p_rob * (p_break * loss_if_breaks + (1 - p_break) * profit_if_sold)\n",
        "\n",
        "# Calculating expected utility if Lisa drops the QA process at low flow rate.\n",
        "expected_utility_drop_low_flow = 0\n",
        "for robustness, p_rob in p_robustness_drop_low_flow.items():\n",
        "    p_break = p_breaks[robustness]\n",
        "    expected_utility_drop_low_flow += p_rob * (p_break * loss_if_breaks + (1 - p_break) * profit_if_sold)\n"
      ],
      "metadata": {
        "id": "ibxx9ejmdfos"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying expected utilities for both scenarios at low flow rate.\n",
        "print(f\"Expected utility if Lisa keeps QA with low flow rate: £{expected_utility_keep_low_flow:.2f}\")\n",
        "print(f\"Expected utility if Lisa drops QA with low flow rate: £{expected_utility_drop_low_flow:.2f}\")\n",
        "\n",
        "# Calculating the improvement worth to Lisa per product based on the difference in expected utility.\n",
        "improvement_worth = max(expected_utility_keep_low_flow, expected_utility_drop_low_flow) - max(expected_utility_keep, expected_utility_drop)\n",
        "\n",
        "# Displaying the improvement worth.\n",
        "print(f\"Improvement worth to Lisa (per product): £{improvement_worth:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FVW2Lkfsdg0m",
        "outputId": "106dadf4-038e-4092-efc2-980289e910c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected utility if Lisa keeps QA with low flow rate: £-220.00\n",
            "Expected utility if Lisa drops QA with low flow rate: £-2680.00\n",
            "Improvement worth to Lisa (per product): £540.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the probability distributions for robustness at different temperatures: low, medium, and high.\n",
        "p_robustness_temp = {\n",
        "    \"low\": {\"Weak\": 0.2, \"Moderate\": 0.5, \"Strong\": 0.3},\n",
        "    \"medium\": {\"Weak\": 0.1, \"Moderate\": 0.4, \"Strong\": 0.5},\n",
        "    \"high\": {\"Weak\": 0.05, \"Moderate\": 0.3, \"Strong\": 0.65}\n",
        "}\n"
      ],
      "metadata": {
        "id": "p9lAG6c5dmHB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the expected utility for each temperature scenario.\n",
        "expected_utility_temp = {}\n",
        "for temp, p_rob in p_robustness_temp.items():\n",
        "    expected_utility_temp[temp] = 0\n",
        "    for robustness, p_rob_val in p_rob.items():\n",
        "        p_break = p_breaks[robustness]\n",
        "        expected_utility_temp[temp] += p_rob_val * (p_break * loss_if_breaks + (1 - p_break) * profit_if_sold)\n"
      ],
      "metadata": {
        "id": "KfYf3v1AdnRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying the expected utility for each temperature scenario.\n",
        "for temp, utility in expected_utility_temp.items():\n",
        "    print(f\"Expected utility for {temp} temperature: £{utility:.2f}\")\n",
        "\n",
        "# Calculating the total expected utility with selective QA.\n",
        "total_expected_utility_selective = sum(expected_utility_temp.values()) / len(expected_utility_temp)\n",
        "print(f\"Total expected utility with selective QA: £{total_expected_utility_selective:.2f}\")\n",
        "\n",
        "# Calculating the worth of sharing temperature information (per product).\n",
        "worth_selective_qa = total_expected_utility_selective - max(expected_utility_keep, expected_utility_drop)\n",
        "print(f\"Worth of sharing temperature information (per product): £{worth_selective_qa:.2f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDvhameEdolI",
        "outputId": "461c7640-ec84-4039-e153-95e5164a35c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Expected utility for low temperature: £-2080.00\n",
            "Expected utility for medium temperature: £-1000.00\n",
            "Expected utility for high temperature: £-340.00\n",
            "Total expected utility with selective QA: £-1140.00\n",
            "Worth of sharing temperature information (per product): £-380.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Question 5"
      ],
      "metadata": {
        "id": "UjXx_PknenPD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Importing necessary libraries for Bayesian network creation and visualization.\n",
        "import pyAgrum as gum\n",
        "import pyAgrum.lib.notebook as gnb\n",
        "from IPython.display import Image\n",
        "\n",
        "# Creating a new Bayesian network called 'DrugEffectiveness'.\n",
        "bn = gum.BayesNet('DrugEffectiveness')\n"
      ],
      "metadata": {
        "id": "aRcJ-Iq5dsxR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining and adding nodes to the Bayesian network:\n",
        "# - 'Diagnosis Time' with two possible states: 'Early' and 'Late'\n",
        "Diagnosis_Time = bn.add(gum.LabelizedVariable('Diagnosis Time', 'Diagnosis Time', ['Early', 'Late']))\n",
        "\n",
        "# - 'Drug Given' with two possible drugs: 'A' and 'B'\n",
        "Drug_Given = bn.add(gum.LabelizedVariable('Drug Given', 'Drug Given', ['A', 'B']))\n",
        "\n",
        "# - 'Recovery' with two possible outcomes: 'Yes' and 'No'\n",
        "Recovery = bn.add(gum.LabelizedVariable('Recovery', 'Recovery', ['Yes', 'No']))\n",
        "\n",
        "# Adding directed arcs to represent relationships between variables:\n",
        "bn.addArc(Diagnosis_Time, Drug_Given)\n",
        "bn.addArc(Diagnosis_Time, Recovery)\n",
        "bn.addArc(Drug_Given, Recovery)\n"
      ],
      "metadata": {
        "id": "h4oZO-2lduCh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining Conditional Probability Tables (CPT) for each variable:\n",
        "bn.cpt(Diagnosis_Time).fillWith([0.6, 0.4])  # Probability for 'Diagnosis Time'\n",
        "\n",
        "bn.cpt(Drug_Given)[{'Diagnosis Time': 'Early'}] = [0.9, 0.1]  # Probabilities for 'Drug Given' given 'Early' Diagnosis Time\n",
        "bn.cpt(Drug_Given)[{'Diagnosis Time': 'Late'}] = [0.4, 0.6]   # Probabilities for 'Drug Given' given 'Late' Diagnosis Time\n",
        "\n",
        "bn.cpt(Recovery)[{'Diagnosis Time': 'Early', 'Drug Given': 'A'}] = [0.8, 0.2]  # 'Recovery' probabilities for 'Early' Diagnosis Time and 'Drug A'\n",
        "bn.cpt(Recovery)[{'Diagnosis Time': 'Early', 'Drug Given': 'B'}] = [0.9, 0.1]  # 'Recovery' probabilities for 'Early' Diagnosis Time and 'Drug B'\n",
        "bn.cpt(Recovery)[{'Diagnosis Time': 'Late', 'Drug Given': 'A'}] = [0.5, 0.5]   # 'Recovery' probabilities for 'Late' Diagnosis Time and 'Drug A'\n",
        "bn.cpt(Recovery)[{'Diagnosis Time': 'Late', 'Drug Given': 'B'}] = [0.6, 0.4]   # 'Recovery' probabilities for 'Late' Diagnosis Time and 'Drug B'\n",
        "\n",
        "# Visualizing the Bayesian network\n",
        "gnb.showBN(bn)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "d3r2PyvKdvUd",
        "outputId": "e4bdc1ad-32ff-474f-97e3-3708c823edb6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.SVG object>"
            ],
            "image/svg+xml": "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" width=\"168pt\" height=\"188pt\" viewBox=\"0.00 0.00 167.59 188.00\">\n<g id=\"graph0\" class=\"graph\" transform=\"scale(1 1) rotate(0) translate(4 184)\">\n<title>G</title>\n<!-- Diagnosis Time -->\n<g id=\"node1\" class=\"node\">\n<title>Diagnosis Time</title>\n<g id=\"a_node1\"><a xlink:title=\"(0) Diagnosis Time\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"92.65\" cy=\"-162\" rx=\"66.89\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.65\" y=\"-158.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Diagnosis Time</text>\n</a>\n</g>\n</g>\n<!-- Drug Given -->\n<g id=\"node2\" class=\"node\">\n<title>Drug Given</title>\n<g id=\"a_node2\"><a xlink:title=\"(1) Drug Given\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"52.65\" cy=\"-90\" rx=\"52.79\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"52.65\" y=\"-86.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Drug Given</text>\n</a>\n</g>\n</g>\n<!-- Diagnosis Time&#45;&gt;Drug Given -->\n<g id=\"edge1\" class=\"edge\">\n<title>Diagnosis Time-&gt;Drug Given</title>\n<g id=\"a_edge1\"><a xlink:title=\"0 → 1\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M82.96,-144.05C78.25,-135.8 72.47,-125.7 67.24,-116.54\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"70.24,-114.73 62.24,-107.79 64.16,-118.21 70.24,-114.73\"/>\n</a>\n</g>\n</g>\n<!-- Recovery -->\n<g id=\"node3\" class=\"node\">\n<title>Recovery</title>\n<g id=\"a_node3\"><a xlink:title=\"(2) Recovery\">\n<ellipse fill=\"#404040\" stroke=\"#4a4a4a\" cx=\"92.65\" cy=\"-18\" rx=\"44.39\" ry=\"18\"/>\n<text text-anchor=\"middle\" x=\"92.65\" y=\"-14.3\" font-family=\"Times,serif\" font-size=\"14.00\" fill=\"white\">Recovery</text>\n</a>\n</g>\n</g>\n<!-- Diagnosis Time&#45;&gt;Recovery -->\n<g id=\"edge2\" class=\"edge\">\n<title>Diagnosis Time-&gt;Recovery</title>\n<g id=\"a_edge2\"><a xlink:title=\"0 → 2\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M101.78,-143.88C106.65,-133.76 112.15,-120.51 114.65,-108 117.77,-92.31 117.77,-87.69 114.65,-72 112.83,-62.87 109.4,-53.35 105.79,-44.93\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"108.89,-43.29 101.55,-35.65 102.52,-46.2 108.89,-43.29\"/>\n</a>\n</g>\n</g>\n<!-- Drug Given&#45;&gt;Recovery -->\n<g id=\"edge3\" class=\"edge\">\n<title>Drug Given-&gt;Recovery</title>\n<g id=\"a_edge3\"><a xlink:title=\"1 → 2\">\n<path fill=\"none\" stroke=\"#4a4a4a\" d=\"M62.33,-72.05C67.04,-63.8 72.82,-53.7 78.05,-44.54\"/>\n<polygon fill=\"#4a4a4a\" stroke=\"#4a4a4a\" points=\"81.13,-46.21 83.05,-35.79 75.05,-42.73 81.13,-46.21\"/>\n</a>\n</g>\n</g>\n</g>\n</svg>"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining probabilities for Diagnosis Time and Drug Given based on previous assumptions\n",
        "P_D_early = 0.6  # Probability that the diagnosis is made early\n",
        "P_D_late = 0.4   # Probability that the diagnosis is made late\n",
        "\n",
        "P_GA_given_D_early = 0.9  # Probability of giving drug A if diagnosed early\n",
        "P_GB_given_D_early = 0.1  # Probability of giving drug B if diagnosed early\n",
        "P_GA_given_D_late = 0.4   # Probability of giving drug A if diagnosed late\n",
        "P_GB_given_D_late = 0.6   # Probability of giving drug B if diagnosed late\n",
        "\n",
        "# Defining probabilities of not recovering given diagnosis and drug combination\n",
        "P_R_no_given_D_early_GA = 0.2  # Probability of not recovering with Drug A and early diagnosis\n",
        "P_R_no_given_D_early_GB = 0.1  # Probability of not recovering with Drug B and early diagnosis\n",
        "P_R_no_given_D_late_GA = 0.5   # Probability of not recovering with Drug A and late diagnosis\n",
        "P_R_no_given_D_late_GB = 0.4   # Probability of not recovering with Drug B and late diagnosis\n"
      ],
      "metadata": {
        "id": "k14Rd_5ld4sD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the probability of giving drug A or drug B based on diagnosis time\n",
        "P_GA = (P_GA_given_D_early * P_D_early) + (P_GA_given_D_late * P_D_late)\n",
        "P_GB = (P_GB_given_D_early * P_D_early) + (P_GB_given_D_late * P_D_late)\n",
        "\n",
        "# Calculating joint probability of not recovering and receiving each drug\n",
        "P_R_no_and_GA = (P_R_no_given_D_early_GA * P_GA_given_D_early * P_D_early) + \\\n",
        "                (P_R_no_given_D_late_GA * P_GA_given_D_late * P_D_late)\n",
        "\n",
        "P_R_no_and_GB = (P_R_no_given_D_early_GB * P_GB_given_D_early * P_D_early) + \\\n",
        "                (P_R_no_given_D_late_GB * P_GB_given_D_late * P_D_late)\n"
      ],
      "metadata": {
        "id": "Hfgr7RjAd52R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Calculating the conditional probabilities of not recovering given each drug\n",
        "P_R_no_given_GA = P_R_no_and_GA / P_GA\n",
        "P_R_no_given_GB = P_R_no_and_GB / P_GB\n",
        "\n",
        "# Displaying the absolute risks of not recovering with each drug\n",
        "print(\"Part b) Absolute Risks of Not Recovering:\")\n",
        "\n",
        "print(f\"Drug A: {P_R_no_given_GA:.4f} ({P_R_no_given_GA * 100:.2f}%)\")\n",
        "print(f\"Drug B: {P_R_no_given_GB:.4f} ({P_R_no_given_GB * 100:.2f}%)\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CJhjoh1Md7KV",
        "outputId": "00b369fb-dd4d-43a5-8a77-25a2ebdd4c63"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Part b) Absolute Risks of Not Recovering:\n",
            "Drug A: 0.2686 (26.86%)\n",
            "Drug B: 0.3400 (34.00%)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Assigning the absolute risk of not recovering for Drug A and Drug B (calculated earlier)\n",
        "absolute_risk_A = P_R_no_given_GA\n",
        "absolute_risk_B = P_R_no_given_GB\n",
        "\n",
        "# Calculating the overall recovery rate for each drug (1 - absolute risk)\n",
        "recovery_rate_A_overall = 1 - absolute_risk_A\n",
        "recovery_rate_B_overall = 1 - absolute_risk_B\n"
      ],
      "metadata": {
        "id": "eqkIlFTEeAzu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Defining the conditional recovery rates based on diagnosis time and drug given\n",
        "P_R_yes_given_D_early_GA = 0.8  # Recovery rate for Drug A with early diagnosis\n",
        "P_R_yes_given_D_early_GB = 0.9  # Recovery rate for Drug B with early diagnosis\n",
        "P_R_yes_given_D_late_GA = 0.5   # Recovery rate for Drug A with late diagnosis\n",
        "P_R_yes_given_D_late_GB = 0.6   # Recovery rate for Drug B with late diagnosis\n"
      ],
      "metadata": {
        "id": "MFZBpU7PeCKA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Displaying overall recovery rates for both drugs\n",
        "print(\"\\nPart c) Analysis of Doctor's Conclusion:\")\n",
        "print(f\"Overall recovery rate with Drug A: {recovery_rate_A_overall:.4f} ({recovery_rate_A_overall * 100:.2f}%)\")\n",
        "print(f\"Overall recovery rate with Drug B: {recovery_rate_B_overall:.4f} ({recovery_rate_B_overall * 100:.2f}%)\")\n",
        "\n",
        "# Displaying conditional recovery rates for early and late diagnosis\n",
        "print(\"\\nConditional recovery rates:\")\n",
        "print(f\"Early Diagnosis - Drug A: {P_R_yes_given_D_early_GA * 100:.0f}%, Drug B: {P_R_yes_given_D_early_GB * 100:.0f}%\")\n",
        "print(f\"Late Diagnosis  - Drug A: {P_R_yes_given_D_late_GA * 100:.0f}%, Drug B: {P_R_yes_given_D_late_GB * 100:.0f}%\")\n",
        "\n",
        "# Analyzing the doctor's conclusion\n",
        "if recovery_rate_A_overall > recovery_rate_B_overall:\n",
        "    print(\"\\nThe doctor concludes Drug A is more effective based on overall recovery rates.\")\n",
        "    print(\"Is he right? No, because:\")\n",
        "    print(\"- Drug B has higher recovery rates in both early (90% vs 80%) and late (60% vs 50%) diagnoses.\")\n",
        "    print(\"- The overall rate favors Drug A due to its frequent use in early cases (90% of early vs 40% of late),\")\n",
        "    print(\"  where recovery is easier, skewing the results.\")\n",
        "    print(\"Phenomenon: Simpson's Paradox\")\n",
        "else:\n",
        "    print(\"Unexpected result: Check calculations.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y-YQgT4meDdA",
        "outputId": "3d1e24b6-7f1a-480c-c234-cc1ef50a3dbc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Part c) Analysis of Doctor's Conclusion:\n",
            "Overall recovery rate with Drug A: 0.7314 (73.14%)\n",
            "Overall recovery rate with Drug B: 0.6600 (66.00%)\n",
            "\n",
            "Conditional recovery rates:\n",
            "Early Diagnosis - Drug A: 80%, Drug B: 90%\n",
            "Late Diagnosis  - Drug A: 50%, Drug B: 60%\n",
            "\n",
            "The doctor concludes Drug A is more effective based on overall recovery rates.\n",
            "Is he right? No, because:\n",
            "- Drug B has higher recovery rates in both early (90% vs 80%) and late (60% vs 50%) diagnoses.\n",
            "- The overall rate favors Drug A due to its frequent use in early cases (90% of early vs 40% of late),\n",
            "  where recovery is easier, skewing the results.\n",
            "Phenomenon: Simpson's Paradox\n"
          ]
        }
      ]
    }
  ]
}